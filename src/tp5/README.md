x = self.conv1(x)
x = F.max_pool2d(F.relu(x), 2)
...
x = torch.flatten(x, 1)
print(x.shape)  # affiche [batch_size, flatten_size]



ParamÃ¨tres de ton CNN

Input : 3 Ã— 256 Ã— 256

Conv1 : 3 â†’ 6, kernel 5, padding 1

Taille : (256 - 5 + 2*1)/1 + 1 = 254

AprÃ¨s MaxPool 2Ã—2 : 254 / 2 = 127 â†’ 6 Ã— 127 Ã— 127

Conv2 : 6 â†’ 12, kernel 5, padding 1

Conv : (127 - 5 + 2*1)/1 + 1 = 125

MaxPool 2Ã—2 : 125 / 2 = 62 (entier tronquÃ©) â†’ 12 Ã— 62 Ã— 62

Conv3 : 12 â†’ 24, kernel 5, padding 1

Conv : (62 - 5 + 2)/1 + 1 = 60

MaxPool 2Ã—2 : 60 / 2 = 30 â†’ 24 Ã— 30 Ã— 30

Conv4 : 24 â†’ 48, kernel 5, padding 1

Conv : (30 - 5 + 2)/1 + 1 = 28

MaxPool 2Ã—2 : 28 / 2 = 14 â†’ 48 Ã— 14 Ã— 14

Conv5 : 48 â†’ 192, kernel 5, padding 1

Conv : (14 - 5 + 2)/1 + 1 = 12

AvgPool 2Ã—2 : 12 / 2 = 6

AvgPool 2Ã—2 encore : 6 / 2 = 3 â†’ 192 Ã— 3 Ã— 3 = 1728

âœ… Donc, le flatten avant la premiÃ¨re couche fully connected doit Ãªtre 192 Ã— 3 Ã— 3 = 1728, et non 76800 comme dans ton code actuel.






I. Dimensionnement des couches du CNN

Ton rÃ©seau Net est structurÃ© ainsi :

Input: Image RGB 30x30
Conv1: 3 -> 6, kernel 5x5, padding=1
MaxPool: 2x2
Conv2: 6 -> 12, kernel 5x5, padding=1
MaxPool: 2x2
Conv3: 12 -> 24, kernel 5x5, padding=1
MaxPool: 2x2
Conv4: 24 -> 48, kernel 5x5, padding=1
MaxPool: 2x2
Conv5: 48 -> 192, kernel 5x5, padding=1
AvgPool: 2x2
Flatten
FC1: 76800 -> 1024
FC2: 1024 -> 512
FC_out: 512 -> 4

ğŸ”¹ Comment calculer les tailles intermÃ©diaires

Pour une convolution 2D :

ğ‘‚
=
ğ‘Š
âˆ’
ğ¾
+
2
ğ‘ƒ
ğ‘†
+
1
O=
S
Wâˆ’K+2P
	â€‹

+1

oÃ¹ :

W = taille dâ€™entrÃ©e

K = taille du kernel

P = padding

S = stride

Et pour le pooling 2x2 (stride=2) : on divise la dimension par 2.

Exemple pour Conv1 + MaxPool :

Input : 30x30

Conv1 (kernel=5, padding=1, stride=1) :

ğ‘‚
=
30
âˆ’
5
+
2
âˆ—
1
1
+
1
=
28
O=
1
30âˆ’5+2âˆ—1
	â€‹

+1=28

MaxPool 2x2 : 28/2 = 14

Channels : 6 â†’ output = (6, 14, 14)

En rÃ©pÃ©tant ce calcul couche par couche, tu peux vÃ©rifier que le flatten donne bien 76800 entrÃ©es pour FC1.

ğŸ’¡ Astuce : pour Ã©viter les erreurs, imprime les tailles aprÃ¨s chaque couche :

print(x.shape)